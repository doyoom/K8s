apiVersion: v1
kind: Pod
metadata:
  name: spark-streaming
  namespace: default
spec:
  serviceAccountName: spark
  containers:
  - name: spark
    image: doyoomii/spark-k8s:latest
    imagePullPolicy: Always
    env:
    - name: KAFKA_BOOTSTRAP_SERVERS
      value: "streaming-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092"
    command: ["/opt/spark/bin/spark-submit"]
    args:
      - "--master"
      - "local[*]"
      - "--packages"
      - "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.hadoop:hadoop-aws:3.3.4,org.apache.hadoop:hadoop-common:3.3.4"
      - "--conf"
      - "spark.driver.extraJavaOptions=-Divy.cache.dir=/tmp -Divy.home=/tmp"
      - "--conf"
      - "spark.hadoop.fs.s3a.endpoint=http://minio.storage.svc.cluster.local:9000"
      - "--conf"
      - "spark.hadoop.fs.s3a.access.key=admin"
      - "--conf"
      - "spark.hadoop.fs.s3a.secret.key=password1234"
      - "--conf"
      - "spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem"
      - "--conf"
      - "spark.hadoop.fs.s3a.path.style.access=true"
      - "/opt/spark/code/user_activity_streaming.py"
    volumeMounts:
      - name: spark-code
        mountPath: /opt/spark/code
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
  volumes:
    - name: spark-code
      configMap:
        name: spark-app-code
  restartPolicy: OnFailure
